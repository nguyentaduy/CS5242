{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent, Bidirectional, Dense, Flatten, Dropout, LSTM, GRU, Conv1D, MaxPooling1D, UpSampling1D,BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "import string\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def get_dictionary(vocab):\n",
    "    d = dict()\n",
    "    with open(vocab, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            w = l.strip().split()\n",
    "            k = w[0]\n",
    "            v = []\n",
    "            for i in range(1, len(w)):\n",
    "                v.append(float(w[i]))\n",
    "            d[k] = np.array(v, dtype=np.float32)\n",
    "    return d\n",
    "def tokenize_sequence(seq, max_length, dim):\n",
    "    words = word_tokenize(seq.lower())\n",
    "    word_vectors = list(map(lambda x: d[x] if x in d else np.zeros(dim), words))\n",
    "    for i in range(len(word_vectors), max_length):\n",
    "        word_vectors.append(np.zeros(dim))\n",
    "    word_vectors = word_vectors[:max_length]\n",
    "    return np.array(word_vectors)\n",
    "def create_one_hot_answer(para, answer, answer_start, option, max_length):\n",
    "    if option == \"s\":\n",
    "        from_begin = para[0:answer_start]\n",
    "    else:\n",
    "        from_begin = para[0:answer_start+len(answer)]\n",
    "    l = len(word_tokenize(from_begin))\n",
    "    one_hot = np.zeros(max_length)\n",
    "    if option == \"s\":\n",
    "        one_hot[min(l, max_length - 1)] = 1\n",
    "    else:\n",
    "        one_hot[min(l - 1, max_length-1)] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = get_dictionary(\"glove/glove.6B.200d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "ids = []\n",
    "titles = dict()\n",
    "contexts = dict()\n",
    "questions = dict()\n",
    "answers_text = dict()\n",
    "answers_start = dict()\n",
    "for i in range(len(data)):\n",
    "    paragraphs = data[i][\"paragraphs\"]\n",
    "    title = data[i][\"title\"]\n",
    "    for j in range(len(paragraphs)):\n",
    "        context = paragraphs[j][\"context\"]\n",
    "        qas = paragraphs[j][\"qas\"]\n",
    "        for k in range(len(qas)):\n",
    "            id_ = qas[k][\"id\"]\n",
    "            answer = qas[k][\"answer\"]\n",
    "            question = qas[k][\"question\"]\n",
    "            ids.append(id_)\n",
    "            titles[id_] = title\n",
    "            contexts[id_] = context\n",
    "            answers_start[id_] = answer[\"answer_start\"]\n",
    "            answers_text[id_] = answer[\"text\"]\n",
    "            questions[id_] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_para = 664\n",
    "max_q = 50\n",
    "dimension = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [i for i in range(len(ids))]\n",
    "t.sort(key=lambda x: np.random.random())\n",
    "ind = t[:len(questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paras = [tokenize_sequence(contexts[ids[ind[i]]],max_para,dimension) for i in range(len(ind))]\n",
    "qns = [tokenize_sequence(questions[ids[ind[i]]],max_q,dimension) for i in range(len(ind))]\n",
    "ans_starts = [create_one_hot_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], \"s\", max_para) for i in range(len(ind))]\n",
    "ans_ends = [create_one_hot_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], \"e\", max_para) for i in range(len(ind))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 100)\n"
     ]
    }
   ],
   "source": [
    "sentence = layers.Input(shape=(max_para,dimension), dtype='float32')\n",
    "encoded_sentence = GRU(100, return_sequences=True)(sentence)\n",
    "print(encoded_sentence.shape)\n",
    "question = layers.Input(shape=(max_q,dimension), dtype='float32')\n",
    "encoded_question = GRU(100, return_sequences=True)(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 100)\n"
     ]
    }
   ],
   "source": [
    "merge_1 = layers.dot([encoded_sentence, encoded_question], axes = 2 )\n",
    "A_Q = layers.Activation(\"softmax\")(merge_1)\n",
    "merge_2 = layers.dot([encoded_question, encoded_sentence], axes = 2 )\n",
    "A_D = layers.Activation(\"softmax\")(merge_2)\n",
    "C_Q = layers.dot([A_Q, encoded_sentence], axes = 1 )\n",
    "print(C_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 300)\n"
     ]
    }
   ],
   "source": [
    "C_Q = layers.concatenate([encoded_question, C_Q], axis=2)\n",
    "C_D = layers.dot([A_D, C_Q], axes=1)\n",
    "C_ = layers.concatenate([encoded_sentence, C_D], axis=2)\n",
    "print(C_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 100)\n"
     ]
    }
   ],
   "source": [
    "U = Bidirectional(LSTM(50, return_sequences=True))(C_)\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convoluion, batch norm, relu unit\n",
    "def convBN_pool(input_layer, conv_channels):\n",
    "    convlayer = Conv1D(conv_channels, 1, padding = 'valid', strides = 2)(input_layer)\n",
    "    BN = BatchNormalization(axis=-1, momentum = 0.99, epsilon=0.001, center=True, scale = True, \n",
    "                            beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', \n",
    "                            beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(convlayer)\n",
    "    activation = Activation('elu')(BN)\n",
    "\n",
    "    return activation\n",
    "\n",
    "def convBN(input_layer, conv_channels):\n",
    "    convlayer = Conv1D(conv_channels, 3, padding = 'same')(input_layer)\n",
    "    BN = BatchNormalization(axis=-1, momentum = 0.99, epsilon=0.001, center=True, scale = True, \n",
    "                            beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', \n",
    "                            beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(convlayer)\n",
    "    activation = Activation('elu')(BN)\n",
    "\n",
    "    return activation\n",
    "\n",
    "def RU(input_layer, conv_channels, d_rate):\n",
    "    # input tensor for a 3-channel 256x256 image\n",
    "    x = input_layer\n",
    "    # 3x3 conv with 3 output channels (same as input channels)\n",
    "    y = Conv1D(conv_channels, 3, padding='same', dilation_rate = d_rate)(x)\n",
    "    y = Conv1D(conv_channels, 3, padding='same', dilation_rate = d_rate)(y)\n",
    "    # this returns x + y.\n",
    "    z = layers.add([x, y])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = convBN(U, 100)\n",
    "start = RU(start, 100, 1)\n",
    "start = Dropout(0.5)(start)\n",
    "start = convBN_pool(start, 64)\n",
    "start = RU(start, 64, 2)\n",
    "start = convBN_pool(start, 128)\n",
    "start = RU(start, 128, 2)\n",
    "start = convBN_pool(start, 128)\n",
    "start = RU(start, 128, 2)\n",
    "start = convBN_pool(start, 256)\n",
    "start = RU(start, 256, 2)\n",
    "start = Flatten()(start)\n",
    "start = Dropout(0.5)(start)\n",
    "start = Dense(max_para, activation='softmax', name='output_1')(start)\n",
    "\n",
    "\n",
    "end = GRU(100, return_sequences=True)(U)\n",
    "end = convBN(end, 100)\n",
    "end = RU(end, 100, 1)\n",
    "end = Dropout(0.5)(end)\n",
    "end = convBN_pool(end, 64)\n",
    "end = RU(end, 64, 2)\n",
    "end = convBN_pool(end, 128)\n",
    "end = RU(end, 128, 2)\n",
    "end = convBN_pool(end, 128)\n",
    "end = RU(end, 128, 2)\n",
    "end = convBN_pool(end, 256)\n",
    "end = RU(end, 256, 2)\n",
    "end = Flatten()(end)\n",
    "end = Dropout(0.5)(end)\n",
    "end = Dense(max_para, activation='softmax', name='output_2')(end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([sentence, question],[start, end])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output_1': 'categorical_crossentropy', 'output_2': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(paras)\n",
    "xq = np.array(qns)\n",
    "ans_s = np.array(ans_starts)\n",
    "ans_e = np.array(ans_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 664, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 50, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_10 (GRU)                     (None, 664, 100)      90300                                        \n",
      "____________________________________________________________________________________________________\n",
      "gru_11 (GRU)                     (None, 50, 100)       90300                                        \n",
      "____________________________________________________________________________________________________\n",
      "dot_13 (Dot)                     (None, 664, 50)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 664, 50)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_14 (Dot)                     (None, 50, 664)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_15 (Dot)                     (None, 50, 100)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 50, 664)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 50, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_16 (Dot)                     (None, 664, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 664, 300)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional)  (None, 664, 100)      140400                                       \n",
      "____________________________________________________________________________________________________\n",
      "gru_12 (GRU)                     (None, 664, 100)      60300                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)              (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 664, 100)      400                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 664, 100)      400                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)              (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)              (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_29 (Add)                     (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_34 (Add)                     (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)               (None, 332, 64)       6464                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)              (None, 332, 64)       6464                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 332, 64)       256                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 332, 64)       256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 332, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 332, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)               (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)              (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)               (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)              (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_30 (Add)                     (None, 332, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_35 (Add)                     (None, 332, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)               (None, 166, 128)      8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)              (None, 166, 128)      8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 166, 128)      512                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 166, 128)      512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 166, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 166, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)               (None, 166, 128)      49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)              (None, 166, 128)      49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)               (None, 166, 128)      49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)              (None, 166, 128)      49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_31 (Add)                     (None, 166, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_36 (Add)                     (None, 166, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)               (None, 83, 128)       16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)              (None, 83, 128)       16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 83, 128)       512                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 83, 128)       512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)              (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)              (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_32 (Add)                     (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_37 (Add)                     (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)               (None, 42, 256)       33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)              (None, 42, 256)       33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 42, 256)       1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 42, 256)       1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)               (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)              (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)              (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)              (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_33 (Add)                     (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_38 (Add)                     (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 10752)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 10752)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 10752)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 10752)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "output_1 (Dense)                 (None, 664)           7139992                                      \n",
      "____________________________________________________________________________________________________\n",
      "output_2 (Dense)                 (None, 664)           7139992                                      \n",
      "====================================================================================================\n",
      "Total params: 16,207,036.0\n",
      "Trainable params: 16,204,332.0\n",
      "Non-trainable params: 2,704.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-437440fcd987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/keras/utils/vis_utils.pyc\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/pydot.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mdot_fd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mdot_fd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0mdot_fd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/pydot.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1988\u001b[0m             \u001b[0mcmdline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m             \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1990\u001b[0;31m             stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m         \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mp2cread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2cwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 errread, errwrite)\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Preserve original exception in case os.close raises.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mgc_was_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 49103 samples, validate on 12276 samples\n",
      "Epoch 1/10\n",
      "49103/49103 [==============================] - 1305s - loss: 8.0058 - output_1_loss: 3.9474 - output_2_loss: 4.0583 - output_1_acc: 0.0663 - output_2_acc: 0.0533 - val_loss: 8.3351 - val_output_1_loss: 4.1538 - val_output_2_loss: 4.1813 - val_output_1_acc: 0.0661 - val_output_2_acc: 0.0492\n",
      "Epoch 2/10\n",
      "49103/49103 [==============================] - 1257s - loss: 7.5676 - output_1_loss: 3.7280 - output_2_loss: 3.8396 - output_1_acc: 0.0885 - output_2_acc: 0.0750 - val_loss: 8.2121 - val_output_1_loss: 4.0606 - val_output_2_loss: 4.1515 - val_output_1_acc: 0.0819 - val_output_2_acc: 0.0688\n",
      "Epoch 3/10\n",
      "21000/49103 [===========>..................] - ETA: 611s - loss: 7.1288 - output_1_loss: 3.5006 - output_2_loss: 3.6282 - output_1_acc: 0.1139 - output_2_acc: 0.1006"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=350,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=350,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=350,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=350,\n",
    "          epochs=10,\n",
    "          validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=350,\n",
    "          epochs=10,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=350,\n",
    "          epochs=10,\n",
    "          validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=300,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=300,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
