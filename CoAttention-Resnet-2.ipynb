{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent, Bidirectional, Dense, Flatten, Dropout, LSTM, GRU, Conv1D, MaxPooling1D, UpSampling1D,BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "import string\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def get_dictionary(vocab):\n",
    "    d = dict()\n",
    "    with open(vocab, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            w = l.strip().split()\n",
    "            k = w[0]\n",
    "            v = []\n",
    "            for i in range(1, len(w)):\n",
    "                v.append(float(w[i]))\n",
    "            d[k] = np.array(v, dtype=np.float32)\n",
    "    return d\n",
    "def tokenize_sequence(seq, max_length, dim):\n",
    "    words = word_tokenize(seq.lower())\n",
    "    word_vectors = list(map(lambda x: d[x] if x in d else np.zeros(dim), words))\n",
    "    for i in range(len(word_vectors), max_length):\n",
    "        word_vectors.append(np.zeros(dim))\n",
    "    word_vectors = word_vectors[:max_length]\n",
    "    return np.array(word_vectors)\n",
    "def create_one_hot_answer(para, answer, answer_start, option, max_length):\n",
    "    if option == \"s\":\n",
    "        from_begin = para[0:answer_start]\n",
    "    else:\n",
    "        from_begin = para[0:answer_start+len(answer)]\n",
    "    l = len(word_tokenize(from_begin))\n",
    "    one_hot = np.zeros(max_length)\n",
    "    if option == \"s\":\n",
    "        one_hot[min(l, max_length - 1)] = 1\n",
    "    else:\n",
    "        one_hot[min(l - 1, max_length-1)] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = get_dictionary(\"glove/glove.6B.200d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "ids = []\n",
    "titles = dict()\n",
    "contexts = dict()\n",
    "questions = dict()\n",
    "answers_text = dict()\n",
    "answers_start = dict()\n",
    "for i in range(len(data)):\n",
    "    paragraphs = data[i][\"paragraphs\"]\n",
    "    title = data[i][\"title\"]\n",
    "    for j in range(len(paragraphs)):\n",
    "        context = paragraphs[j][\"context\"]\n",
    "        qas = paragraphs[j][\"qas\"]\n",
    "        for k in range(len(qas)):\n",
    "            id_ = qas[k][\"id\"]\n",
    "            answer = qas[k][\"answer\"]\n",
    "            question = qas[k][\"question\"]\n",
    "            ids.append(id_)\n",
    "            titles[id_] = title\n",
    "            contexts[id_] = context\n",
    "            answers_start[id_] = answer[\"answer_start\"]\n",
    "            answers_text[id_] = answer[\"text\"]\n",
    "            questions[id_] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_para = 664\n",
    "max_q = 50\n",
    "dimension = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [i for i in range(len(ids))]\n",
    "t.sort(key=lambda x: np.random.random())\n",
    "ind = t[:len(questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paras = [tokenize_sequence(contexts[ids[ind[i]]],max_para,dimension) for i in range(len(ind))]\n",
    "qns = [tokenize_sequence(questions[ids[ind[i]]],max_q,dimension) for i in range(len(ind))]\n",
    "ans_starts = [create_one_hot_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], \"s\", max_para) for i in range(len(ind))]\n",
    "ans_ends = [create_one_hot_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], \"e\", max_para) for i in range(len(ind))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 200)\n"
     ]
    }
   ],
   "source": [
    "sentence = layers.Input(shape=(max_para,dimension), dtype='float32')\n",
    "encoded_sentence = GRU(200, return_sequences=True)(sentence)\n",
    "print(encoded_sentence.shape)\n",
    "question = layers.Input(shape=(max_q,dimension), dtype='float32')\n",
    "encoded_question = GRU(200, return_sequences=True)(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 200)\n"
     ]
    }
   ],
   "source": [
    "merge_1 = layers.dot([encoded_sentence, encoded_question], axes = 2 )\n",
    "A_Q = layers.Activation(\"softmax\")(merge_1)\n",
    "merge_2 = layers.dot([encoded_question, encoded_sentence], axes = 2 )\n",
    "A_D = layers.Activation(\"softmax\")(merge_2)\n",
    "C_Q = layers.dot([A_Q, encoded_sentence], axes = 1 )\n",
    "print(C_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 600)\n"
     ]
    }
   ],
   "source": [
    "C_Q = layers.concatenate([encoded_question, C_Q], axis=2)\n",
    "C_D = layers.dot([A_D, C_Q], axes=1)\n",
    "C_ = layers.concatenate([encoded_sentence, C_D], axis=2)\n",
    "print(C_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 200)\n"
     ]
    }
   ],
   "source": [
    "U = Bidirectional(LSTM(100, return_sequences=True))(C_)\n",
    "U = Dropout(0.5)(U)\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convoluion, batch norm, relu unit\n",
    "def convBN_pool(input_layer, conv_channels):\n",
    "    convlayer = Conv1D(conv_channels, 1, padding = 'valid', strides = 2)(input_layer)\n",
    "    BN = BatchNormalization(axis=-1, momentum = 0.99, epsilon=0.001, center=True, scale = True, \n",
    "                            beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros')(convlayer)\n",
    "    activation = layers.PReLU()(BN)\n",
    "\n",
    "    return activation\n",
    "\n",
    "def convBN(input_layer, conv_channels):\n",
    "    convlayer = Conv1D(conv_channels, 3, padding = 'same')(input_layer)\n",
    "    BN = BatchNormalization(axis=-1, momentum = 0.99, epsilon=0.001, center=True, scale = True, \n",
    "                            beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', \n",
    "                            beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(convlayer)\n",
    "    activation = layers.PReLU()(BN)\n",
    "\n",
    "    return activation\n",
    "\n",
    "def RU(input_layer, conv_channels, d_rate):\n",
    "    # input tensor for a 3-channel 256x256 image\n",
    "    x = input_layer\n",
    "    # 3x3 conv with 3 output channels (same as input channels)\n",
    "    y = Conv1D(conv_channels, 3, padding='same', dilation_rate = d_rate)(x)\n",
    "    y = Conv1D(conv_channels, 3, padding='same', dilation_rate = d_rate)(y)\n",
    "    # this returns x + y.\n",
    "    z = layers.add([x, y])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = convBN(U, 100)\n",
    "start = RU(start, 100, 1)\n",
    "start = Dropout(0.5)(start)\n",
    "start = convBN_pool(start, 64)\n",
    "start = RU(start, 64, 1)\n",
    "start = convBN_pool(start, 64)\n",
    "start = RU(start, 64, 2)\n",
    "start = convBN_pool(start, 128)\n",
    "start = RU(start, 128, 1)\n",
    "start =layers.PReLU()(start)\n",
    "start = RU(start, 128, 2)\n",
    "start = Dropout(0.5)(start)\n",
    "start = convBN_pool(start, 256)\n",
    "start = RU(start, 256, 2)\n",
    "start = Dropout(0.5)(start)\n",
    "start = convBN_pool(start, 128)\n",
    "start = RU(start, 128, 1)\n",
    "start = layers.PReLU()(start)\n",
    "start = Flatten()(start)\n",
    "start = Dropout(0.5)(start)\n",
    "start = Dense(max_para, activation='softmax', name='output_1')(start)\n",
    "\n",
    "\n",
    "end = GRU(100, return_sequences=True)(U)\n",
    "end = convBN(end, 100)\n",
    "end = RU(end, 100, 1)\n",
    "end = Dropout(0.5)(end)\n",
    "end = convBN_pool(end, 64)\n",
    "end = RU(end, 64, 1)\n",
    "end = convBN_pool(end, 64)\n",
    "end = RU(end, 64, 2)\n",
    "end = convBN_pool(end, 128)\n",
    "end = RU(end, 128, 1)\n",
    "end = layers.PReLU()(end)\n",
    "end = RU(end, 128, 2)\n",
    "end = Dropout(0.5)(end)\n",
    "end = convBN_pool(end, 256)\n",
    "end = RU(end, 256, 2)\n",
    "end = Dropout(0.5)(end)\n",
    "end = convBN_pool(end, 128)\n",
    "end = RU(end, 128, 1)\n",
    "end = layers.PReLU()(end)\n",
    "end = Flatten()(end)\n",
    "end = Dropout(0.5)(end)\n",
    "end = Dense(max_para, activation='softmax', name='output_2')(end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([sentence, question],[start, end])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output_1': 'categorical_crossentropy', 'output_2': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(paras)\n",
    "xq = np.array(qns)\n",
    "ans_s = np.array(ans_starts)\n",
    "ans_e = np.array(ans_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 664, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 50, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 664, 200)      240600                                       \n",
      "____________________________________________________________________________________________________\n",
      "gru_5 (GRU)                      (None, 50, 200)       240600                                       \n",
      "____________________________________________________________________________________________________\n",
      "dot_5 (Dot)                      (None, 664, 50)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 664, 50)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_6 (Dot)                      (None, 50, 664)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_7 (Dot)                      (None, 50, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 50, 664)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 50, 400)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_8 (Dot)                      (None, 664, 400)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 664, 600)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 664, 200)      560800                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 664, 200)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_6 (GRU)                      (None, 664, 100)      90300                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)               (None, 664, 100)      60100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 664, 100)      400                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 664, 100)      400                                          \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_17 (PReLU)               (None, 664, 100)      66400                                        \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_25 (PReLU)               (None, 664, 100)      66400                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)               (None, 664, 100)      30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_22 (Add)                     (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 664, 100)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)               (None, 332, 64)       6464                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)               (None, 332, 64)       6464                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 332, 64)       256                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 332, 64)       256                                          \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_18 (PReLU)               (None, 332, 64)       21248                                        \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_26 (PReLU)               (None, 332, 64)       21248                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)               (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)               (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)               (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)               (None, 332, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 332, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_23 (Add)                     (None, 332, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)               (None, 166, 64)       4160                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)               (None, 166, 64)       4160                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 166, 64)       256                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 166, 64)       256                                          \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_19 (PReLU)               (None, 166, 64)       10624                                        \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_27 (PReLU)               (None, 166, 64)       10624                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)               (None, 166, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)               (None, 166, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)               (None, 166, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)               (None, 166, 64)       12352                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_17 (Add)                     (None, 166, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_24 (Add)                     (None, 166, 64)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)               (None, 83, 128)       8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)               (None, 83, 128)       8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 83, 128)       512                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 83, 128)       512                                          \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_20 (PReLU)               (None, 83, 128)       10624                                        \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_28 (PReLU)               (None, 83, 128)       10624                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_18 (Add)                     (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_25 (Add)                     (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_21 (PReLU)               (None, 83, 128)       10624                                        \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_29 (PReLU)               (None, 83, 128)       10624                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)               (None, 83, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_19 (Add)                     (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_26 (Add)                     (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 83, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)               (None, 42, 256)       33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)               (None, 42, 256)       33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 42, 256)       1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 42, 256)       1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_22 (PReLU)               (None, 42, 256)       10752                                        \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_30 (PReLU)               (None, 42, 256)       10752                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)               (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)               (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)               (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)               (None, 42, 256)       196864                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_20 (Add)                     (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_27 (Add)                     (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 42, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)               (None, 21, 128)       32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)               (None, 21, 128)       32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 21, 128)       512                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 21, 128)       512                                          \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_23 (PReLU)               (None, 21, 128)       2688                                         \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_31 (PReLU)               (None, 21, 128)       2688                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)               (None, 21, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)               (None, 21, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)               (None, 21, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)               (None, 21, 128)       49280                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_21 (Add)                     (None, 21, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_28 (Add)                     (None, 21, 128)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_24 (PReLU)               (None, 21, 128)       2688                                         \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_32 (PReLU)               (None, 21, 128)       2688                                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 2688)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 2688)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 2688)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 2688)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "output_1 (Dense)                 (None, 664)           1785496                                      \n",
      "____________________________________________________________________________________________________\n",
      "output_2 (Dense)                 (None, 664)           1785496                                      \n",
      "====================================================================================================\n",
      "Total params: 6,838,468.0\n",
      "Trainable params: 6,835,508.0\n",
      "Non-trainable params: 2,960.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 55241 samples, validate on 6138 samples\n",
      "Epoch 1/10\n",
      "55241/55241 [==============================] - 1307s - loss: 10.0037 - output_1_loss: 4.9817 - output_2_loss: 5.0220 - output_1_acc: 0.0188 - output_2_acc: 0.0110 - val_loss: 10.3512 - val_output_1_loss: 5.0843 - val_output_2_loss: 5.2669 - val_output_1_acc: 0.0254 - val_output_2_acc: 0.0148\n",
      "Epoch 2/10\n",
      "55241/55241 [==============================] - 1282s - loss: 9.8435 - output_1_loss: 4.9029 - output_2_loss: 4.9406 - output_1_acc: 0.0211 - output_2_acc: 0.0115 - val_loss: 9.8012 - val_output_1_loss: 4.8894 - val_output_2_loss: 4.9118 - val_output_1_acc: 0.0254 - val_output_2_acc: 0.0094\n",
      "Epoch 3/10\n",
      "55241/55241 [==============================] - 1268s - loss: 9.7883 - output_1_loss: 4.8740 - output_2_loss: 4.9143 - output_1_acc: 0.0219 - output_2_acc: 0.0122 - val_loss: 9.7697 - val_output_1_loss: 4.8674 - val_output_2_loss: 4.9024 - val_output_1_acc: 0.0259 - val_output_2_acc: 0.0125\n",
      "Epoch 4/10\n",
      "55241/55241 [==============================] - 1281s - loss: 9.7540 - output_1_loss: 4.8552 - output_2_loss: 4.8987 - output_1_acc: 0.0227 - output_2_acc: 0.0126 - val_loss: 9.7860 - val_output_1_loss: 4.8615 - val_output_2_loss: 4.9245 - val_output_1_acc: 0.0235 - val_output_2_acc: 0.0137\n",
      "Epoch 5/10\n",
      "55241/55241 [==============================] - 1308s - loss: 9.6550 - output_1_loss: 4.8071 - output_2_loss: 4.8479 - output_1_acc: 0.0236 - output_2_acc: 0.0154 - val_loss: 9.9565 - val_output_1_loss: 4.8981 - val_output_2_loss: 5.0585 - val_output_1_acc: 0.0241 - val_output_2_acc: 0.0130\n",
      "Epoch 6/10\n",
      " 3584/55241 [>.............................] - ETA: 1159s - loss: 9.2979 - output_1_loss: 4.6220 - output_2_loss: 4.6758 - output_1_acc: 0.0357 - output_2_acc: 0.0198"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c4183e6df033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               validation_split=val_split)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mval_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "val_split = 0.1\n",
    "for i in range(5):\n",
    "    model.fit([x, xq], [ans_s, ans_e],\n",
    "              batch_size=256,\n",
    "              epochs=10,\n",
    "              validation_split=val_split)\n",
    "    if i == 3:\n",
    "        val_split = 0\n",
    "    model.save(\"model_second.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model_second.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"model_second.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 55241 samples, validate on 6138 samples\n",
      "Epoch 1/5\n",
      "55241/55241 [==============================] - 1753s - loss: 6.9515 - output_1_loss: 3.4225 - output_2_loss: 3.5290 - output_1_acc: 0.1005 - output_2_acc: 0.0838 - val_loss: 7.2504 - val_output_1_loss: 3.6136 - val_output_2_loss: 3.6368 - val_output_1_acc: 0.1075 - val_output_2_acc: 0.1036\n",
      "Epoch 2/5\n",
      "55241/55241 [==============================] - 1784s - loss: 6.3704 - output_1_loss: 3.1463 - output_2_loss: 3.2241 - output_1_acc: 0.1358 - output_2_acc: 0.1303 - val_loss: 7.1017 - val_output_1_loss: 3.5109 - val_output_2_loss: 3.5908 - val_output_1_acc: 0.1429 - val_output_2_acc: 0.1663\n",
      "Epoch 3/5\n",
      "55241/55241 [==============================] - 1885s - loss: 5.8155 - output_1_loss: 2.8984 - output_2_loss: 2.9171 - output_1_acc: 0.1728 - output_2_acc: 0.1989 - val_loss: 6.7653 - val_output_1_loss: 3.3651 - val_output_2_loss: 3.4002 - val_output_1_acc: 0.1598 - val_output_2_acc: 0.2248\n",
      "Epoch 4/5\n",
      "55241/55241 [==============================] - 1856s - loss: 5.3382 - output_1_loss: 2.7040 - output_2_loss: 2.6342 - output_1_acc: 0.2147 - output_2_acc: 0.2783 - val_loss: 6.9225 - val_output_1_loss: 3.3346 - val_output_2_loss: 3.5878 - val_output_1_acc: 0.2095 - val_output_2_acc: 0.2597\n",
      "Epoch 5/5\n",
      "55241/55241 [==============================] - 1990s - loss: 4.9247 - output_1_loss: 2.5089 - output_2_loss: 2.4159 - output_1_acc: 0.2616 - output_2_acc: 0.3506 - val_loss: 6.4542 - val_output_1_loss: 3.2247 - val_output_2_loss: 3.2295 - val_output_1_acc: 0.2441 - val_output_2_acc: 0.2978\n",
      "Train on 55241 samples, validate on 6138 samples\n",
      "Epoch 1/5\n",
      "55241/55241 [==============================] - 2087s - loss: 4.5283 - output_1_loss: 2.3298 - output_2_loss: 2.1985 - output_1_acc: 0.3185 - output_2_acc: 0.4194 - val_loss: 6.8768 - val_output_1_loss: 3.5083 - val_output_2_loss: 3.3685 - val_output_1_acc: 0.2667 - val_output_2_acc: 0.3702\n",
      "Epoch 2/5\n",
      "55241/55241 [==============================] - 2002s - loss: 4.2132 - output_1_loss: 2.1785 - output_2_loss: 2.0347 - output_1_acc: 0.3654 - output_2_acc: 0.4745 - val_loss: 6.8081 - val_output_1_loss: 3.4378 - val_output_2_loss: 3.3703 - val_output_1_acc: 0.2828 - val_output_2_acc: 0.3775\n",
      "Epoch 3/5\n",
      "55241/55241 [==============================] - 1931s - loss: 3.9729 - output_1_loss: 2.0614 - output_2_loss: 1.9115 - output_1_acc: 0.4005 - output_2_acc: 0.5110 - val_loss: 6.9850 - val_output_1_loss: 3.4184 - val_output_2_loss: 3.5666 - val_output_1_acc: 0.3172 - val_output_2_acc: 0.3904\n",
      "Epoch 4/5\n",
      "55241/55241 [==============================] - 1996s - loss: 3.7508 - output_1_loss: 1.9520 - output_2_loss: 1.7988 - output_1_acc: 0.4351 - output_2_acc: 0.5406 - val_loss: 6.4398 - val_output_1_loss: 3.2149 - val_output_2_loss: 3.2249 - val_output_1_acc: 0.3065 - val_output_2_acc: 0.3980\n",
      "Epoch 5/5\n",
      "55241/55241 [==============================] - 2137s - loss: 3.5539 - output_1_loss: 1.8574 - output_2_loss: 1.6965 - output_1_acc: 0.4644 - output_2_acc: 0.5668 - val_loss: 6.6787 - val_output_1_loss: 3.3351 - val_output_2_loss: 3.3436 - val_output_1_acc: 0.3361 - val_output_2_acc: 0.4153\n",
      "Train on 55241 samples, validate on 6138 samples\n",
      "Epoch 1/5\n",
      "55241/55241 [==============================] - 2392s - loss: 3.3572 - output_1_loss: 1.7640 - output_2_loss: 1.5932 - output_1_acc: 0.4940 - output_2_acc: 0.5946 - val_loss: 6.7974 - val_output_1_loss: 3.3378 - val_output_2_loss: 3.4596 - val_output_1_acc: 0.3394 - val_output_2_acc: 0.4228\n",
      "Epoch 2/5\n",
      "55241/55241 [==============================] - 2114s - loss: 3.2061 - output_1_loss: 1.6923 - output_2_loss: 1.5138 - output_1_acc: 0.5108 - output_2_acc: 0.6164 - val_loss: 6.7877 - val_output_1_loss: 3.2690 - val_output_2_loss: 3.5187 - val_output_1_acc: 0.3486 - val_output_2_acc: 0.4233\n",
      "Epoch 3/5\n",
      "55241/55241 [==============================] - 1975s - loss: 3.0571 - output_1_loss: 1.6239 - output_2_loss: 1.4332 - output_1_acc: 0.5317 - output_2_acc: 0.6379 - val_loss: 6.9131 - val_output_1_loss: 3.4011 - val_output_2_loss: 3.5120 - val_output_1_acc: 0.3514 - val_output_2_acc: 0.4335\n",
      "Epoch 4/5\n",
      "55241/55241 [==============================] - 2073s - loss: 2.9240 - output_1_loss: 1.5608 - output_2_loss: 1.3633 - output_1_acc: 0.5496 - output_2_acc: 0.6578 - val_loss: 7.1408 - val_output_1_loss: 3.4544 - val_output_2_loss: 3.6863 - val_output_1_acc: 0.3636 - val_output_2_acc: 0.4402\n",
      "Epoch 5/5\n",
      "55241/55241 [==============================] - 2179s - loss: 2.8278 - output_1_loss: 1.5184 - output_2_loss: 1.3095 - output_1_acc: 0.5661 - output_2_acc: 0.6740 - val_loss: 7.0010 - val_output_1_loss: 3.4532 - val_output_2_loss: 3.5478 - val_output_1_acc: 0.3633 - val_output_2_acc: 0.4374\n",
      "Epoch 1/5\n",
      "61379/61379 [==============================] - 2097s - loss: 3.1851 - output_1_loss: 1.6835 - output_2_loss: 1.5016 - output_1_acc: 0.5521 - output_2_acc: 0.6524  \n",
      "Epoch 2/5\n",
      "61379/61379 [==============================] - 2126s - loss: 2.9461 - output_1_loss: 1.5737 - output_2_loss: 1.3724 - output_1_acc: 0.5702 - output_2_acc: 0.6737  \n",
      "Epoch 3/5\n",
      "61379/61379 [==============================] - 2113s - loss: 2.7771 - output_1_loss: 1.4918 - output_2_loss: 1.2853 - output_1_acc: 0.5872 - output_2_acc: 0.6930  \n",
      "Epoch 4/5\n",
      "61379/61379 [==============================] - 2633s - loss: 2.6758 - output_1_loss: 1.4454 - output_2_loss: 1.2304 - output_1_acc: 0.5990 - output_2_acc: 0.7029  \n",
      "Epoch 5/5\n",
      "61379/61379 [==============================] - 2961s - loss: 3.1154 - output_1_loss: 1.6578 - output_2_loss: 1.4576 - output_1_acc: 0.5528 - output_2_acc: 0.6582  \n",
      "Epoch 1/5\n",
      "61379/61379 [==============================] - 2924s - loss: 2.5814 - output_1_loss: 1.3929 - output_2_loss: 1.1885 - output_1_acc: 0.6108 - output_2_acc: 0.7138  \n",
      "Epoch 2/5\n",
      "61379/61379 [==============================] - 2805s - loss: 2.4137 - output_1_loss: 1.3082 - output_2_loss: 1.1055 - output_1_acc: 0.6324 - output_2_acc: 0.7332  \n",
      "Epoch 3/5\n",
      "61379/61379 [==============================] - 2727s - loss: 2.3010 - output_1_loss: 1.2509 - output_2_loss: 1.0501 - output_1_acc: 0.6442 - output_2_acc: 0.7462  \n",
      "Epoch 4/5\n",
      "61379/61379 [==============================] - 2920s - loss: 2.2569 - output_1_loss: 1.2258 - output_2_loss: 1.0311 - output_1_acc: 0.6555 - output_2_acc: 0.7499  \n",
      "Epoch 5/5\n",
      "61379/61379 [==============================] - 3117s - loss: 2.1855 - output_1_loss: 1.1866 - output_2_loss: 0.9989 - output_1_acc: 0.6665 - output_2_acc: 0.7580  \n"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "val_split = 0.1\n",
    "for i in range(5):\n",
    "    model.fit([x, xq], [ans_s, ans_e],\n",
    "              batch_size=200,\n",
    "              epochs=5,\n",
    "              validation_split=val_split)\n",
    "    if i == 2:\n",
    "        val_split = 0\n",
    "    model.save(\"model_second.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
