{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from functools import reduce\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dictionary(vocab):\n",
    "    d = dict()\n",
    "    with open(vocab, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            w = l.strip().split()\n",
    "            k = w[0]\n",
    "            v = []\n",
    "            for i in range(1, len(w)):\n",
    "                v.append(float(w[i]))\n",
    "            d[k] = np.array(v, dtype=np.float32)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = get_dictionary(\"glove/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sequence(seq, max_length, dim):\n",
    "    words = word_tokenize(seq.lower())\n",
    "    word_vectors = list(map(lambda x: d[x] if x in d else np.zeros(dim), words))\n",
    "    for i in range(len(word_vectors), max_length):\n",
    "        word_vectors.append(np.zeros(dim))\n",
    "    return np.array(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.json') as data_file:    \n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "titles = dict()\n",
    "contexts = dict()\n",
    "questions = dict()\n",
    "answers_text = dict()\n",
    "answers_start = dict()\n",
    "for i in range(len(data)):\n",
    "    paragraphs = data[i][\"paragraphs\"]\n",
    "    title = data[i][\"title\"]\n",
    "    for j in range(len(paragraphs)):\n",
    "        context = paragraphs[j][\"context\"]\n",
    "        qas = paragraphs[j][\"qas\"]\n",
    "        for k in range(len(qas)):\n",
    "            id_ = qas[k][\"id\"]\n",
    "            answer = qas[k][\"answer\"]\n",
    "            question = qas[k][\"question\"]\n",
    "            ids.append(id_)\n",
    "            titles[id_] = title\n",
    "            contexts[id_] = context\n",
    "            answers_start[id_] = answer[\"answer_start\"]\n",
    "            answers_text[id_] = answer[\"text\"]\n",
    "            questions[id_] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_para = 766\n",
    "max_q = 125\n",
    "dimension = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [i for i in range(len(ids))]\n",
    "t.sort(key=lambda x: np.random.random())\n",
    "ind = t[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_one_hot_answer(para, answer, answer_start, option, max_length):\n",
    "    if option == \"s\":\n",
    "        from_begin = para[0:answer_start]\n",
    "    else:\n",
    "        from_begin = para[0:answer_start+len(answer)]\n",
    "    l = len(word_tokenize(from_begin))\n",
    "    one_hot = np.zeros(max_length)\n",
    "    if option == \"s\":\n",
    "        one_hot[l] = 1\n",
    "    else:\n",
    "        one_hot[l - 1] = 1\n",
    "    return one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_bin_answer(para, answer, answer_start, max_length):\n",
    "#     from_begin_s = para[0:answer_start]\n",
    "#     from_begin_e = para[0:answer_start +len(answer)]\n",
    "#     l_s = len(word_tokenize(from_begin_s))\n",
    "#     l_e = len(word_tokenize(from_begin_e))\n",
    "#     bin_ = np.zeros(max_length)\n",
    "#     for i in range(l_s, l_e):\n",
    "#         bin_[i] = 1\n",
    "#     return bin_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paras = [tokenize_sequence(contexts[ids[ind[i]]],max_para,dimension) for i in range(len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qns = [tokenize_sequence(questions[ids[ind[i]]],max_q,dimension) for i in range(len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans_starts = [create_one_hot_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], \"s\", max_para) for i in range(len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans_ends = [create_one_hot_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], \"e\", max_para) for i in range(len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ans = [create_bin_answer(contexts[ids[ind[i]]], answers_text[ids[ind[i]]], answers_start[ids[ind[i]]], max_para) for i in range(len(ind))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "ANS_SIZE = 766\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 50)\n"
     ]
    }
   ],
   "source": [
    "sentence = layers.Input(shape=(max_para,dimension), dtype='float32')\n",
    "encoded_sentence = RNN(EMBED_HIDDEN_SIZE, return_sequences=True)(sentence)\n",
    "print(encoded_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = layers.Input(shape=(max_q,dimension), dtype='float32')\n",
    "encoded_question = RNN(EMBED_HIDDEN_SIZE, return_sequences=True)(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 50)\n"
     ]
    }
   ],
   "source": [
    "merge_1 = layers.dot([encoded_sentence, encoded_question], axes = 2 )\n",
    "A_Q = layers.Activation(\"softmax\")(merge_1)\n",
    "merge_2 = layers.dot([encoded_question, encoded_sentence], axes = 2 )\n",
    "A_D = layers.Activation(\"softmax\")(merge_2)\n",
    "C_Q = layers.dot([merge_1, encoded_sentence], axes = 1 )\n",
    "print(C_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 150)\n"
     ]
    }
   ],
   "source": [
    "C_Q = layers.concatenate([encoded_question, C_Q], axis=2)\n",
    "C_D = layers.dot([A_D, C_Q], axes=1)\n",
    "C_ = layers.concatenate([encoded_sentence, C_D], axis=2)\n",
    "print(C_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 100)\n"
     ]
    }
   ],
   "source": [
    "U = Bidirectional(RNN(EMBED_HIDDEN_SIZE, return_sequences=True))(C_)\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = RNN(ANS_SIZE)(U)\n",
    "decoder_s = layers.Activation(\"softmax\", name=\"output_1\")(decoder)\n",
    "decoder_e = layers.Activation(\"softmax\", name=\"output_2\")(decoder)\n",
    "print(decoder_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model([sentence, question],[decoder_s, decoder_e])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output_1': 'categorical_crossentropy', 'output_2': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(paras)\n",
    "xq = np.array(qns)\n",
    "ans_s = np.array(ans_starts)\n",
    "ans_e = np.array(ans_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/40\n",
      "  96/4500 [..............................] - ETA: 3216s - loss: 14.7120 - output_1_loss: 7.4625 - output_2_loss: 7.2495 - output_1_acc: 0.0000e+00 - output_2_acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "model.fit([x, xq], [ans_s, ans_e],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.tanh(np.array([[1.2,2.3], [2,3]]) + np.array([1.0,2.0]))\n",
    "b = tf.tanh(np.array([1.0,2.0]))\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.73733729  1.96365944]\n",
      " [ 1.75664891  1.96393678]]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default() as s:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2,  4.3],\n",
       "       [ 3. ,  5. ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
